# 🎯 动态 AI 模型配置规则说明

## 📋 基本规则

### 1. 模型标识符规则
- **格式**: 小写字母，可包含数字和下划线
- **位置**: 在 `AI_MODELS` 中定义
- **示例**: `deepseek`, `gemini`, `openrouter`, `huggingface`

### 2. 配置前缀规则
- **格式**: 大写字母 + 下划线
- **模式**: `{MODEL_NAME}_{CONFIG_TYPE}`
- **示例**: `DEEPSEEK_API_KEY`, `GEMINI_MODEL`

### 3. 必需配置项
每个模型都必须包含：
- `{MODEL_NAME}_API_KEY`: API 密钥
- `{MODEL_NAME}_MODEL`: 模型名称

### 4. 可选配置项
- `{MODEL_NAME}_BASE_URL`: API 基础 URL
- `{MODEL_NAME}_DISPLAY_NAME`: 显示名称

## 🔧 配置示例

### 完整配置示例
```env
# 启用模型列表
AI_MODELS=deepseek,gemini,openrouter,huggingface

# DeepSeek 配置
DEEPSEEK_API_KEY=sk-xxx
DEEPSEEK_BASE_URL=https://api.siliconflow.cn/v1
DEEPSEEK_MODEL=deepseek-ai/DeepSeek-V3.2-Exp
DEEPSEEK_DISPLAY_NAME=深度思考 V3.2 (硅基流动)

# Gemini 配置
GEMINI_API_KEY=AIza-xxx
GEMINI_BASE_URL=https://generativelanguage.googleapis.com/v1beta
GEMINI_MODEL=gemini-2.0-flash-exp
GEMINI_DISPLAY_NAME=谷歌双子星

# OpenRouter 配置
OPENROUTER_API_KEY=sk-or-xxx
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
OPENROUTER_MODEL=moonshotai/kimi-k2:free
OPENROUTER_DISPLAY_NAME=kimi-k2 (OpenRouter)

# HuggingFace 配置
HUGGINGFACE_API_KEY=hf-xxx
HUGGINGFACE_BASE_URL=https://router.huggingface.co/v1
HUGGINGFACE_MODEL=deepseek-ai/DeepSeek-V3.2-Exp
HUGGINGFACE_DISPLAY_NAME=DeepSeek V3.2 (HuggingFace)

# 默认模型
DEFAULT_AI_MODEL=deepseek
```

### 最小配置示例
```env
# 最简单的配置（只包含必需项）
AI_MODELS=model1,model2

MODEL1_API_KEY=sk-xxx
MODEL1_MODEL=model-name

MODEL2_API_KEY=AIza-xxx
MODEL2_MODEL=gemini-2.0-flash-exp

DEFAULT_AI_MODEL=model1
```

## 🚀 添加新模型步骤

### 步骤 1: 确定模型标识符
```env
# 例如添加 Claude 模型
AI_MODELS=deepseek,gemini,openrouter,huggingface,claude
```

### 步骤 2: 添加配置项
```env
# Claude 配置
CLAUDE_API_KEY=sk-ant-xxx
CLAUDE_BASE_URL=https://api.anthropic.com/v1
CLAUDE_MODEL=claude-3-5-sonnet-20241022
CLAUDE_DISPLAY_NAME=Claude 3.5 Sonnet
```

### 步骤 3: 测试配置
```bash
# 运行测试脚本
python test_dynamic_config.py

# 或使用 API 测试
curl "http://localhost:5001/api/available_models?reload=true"
```

## ⚠️ 常见错误

### 错误 1: 配置前缀不匹配
```env
# ❌ 错误：标识符和前缀不匹配
AI_MODELS=huggingface
OPENROUTER_API_KEY=hf-xxx  # 应该用 HUGGINGFACE_API_KEY
```

### 错误 2: 缺少必需配置
```env
# ❌ 错误：缺少 API_KEY
AI_MODELS=model1
MODEL1_MODEL=model-name  # 缺少 MODEL1_API_KEY
```

### 错误 3: 大小写错误
```env
# ❌ 错误：大小写不一致
AI_MODELS=DeepSeek  # 应该用小写
DEEPSEEK_API_KEY=sk-xxx  # 前缀正确
```

## 🔍 配置验证

### 自动验证
系统启动时会自动验证：
- ✅ 检查必需配置项是否存在
- ✅ 验证模型是否可用
- ✅ 显示配置错误信息

### 手动验证
```bash
# 运行配置测试
python test_dynamic_config.py

# 检查 API 端点
curl http://localhost:5001/api/available_models
```

## 📊 支持的模型类型

### 当前支持
- ✅ **DeepSeek** (硅基流动)
- ✅ **Google Gemini**
- ✅ **OpenRouter** (各种模型)
- ✅ **HuggingFace** (推理端点)

### 可扩展支持
- 🔄 **Claude** (Anthropic)
- 🔄 **通义千问** (阿里云)
- 🔄 **文心一言** (百度)
- 🔄 **ChatGLM** (智谱AI)
- 🔄 **自定义 API**

## 💡 最佳实践

### 1. 命名规范
- 模型标识符使用有意义的名称
- 显示名称使用用户友好的名称
- 保持配置项命名一致性

### 2. 安全考虑
- 不要将 `.env` 文件提交到 Git
- 使用 `.env.example` 作为模板
- 定期轮换 API 密钥

### 3. 性能优化
- 只配置需要的模型
- 使用可靠的 API 提供商
- 监控 API 使用量和费用

## 🎉 总结

通过遵循这些配置规则，您可以轻松地：
- ✅ 添加新的 AI 模型
- ✅ 自定义模型显示名称
- ✅ 配置不同的 API 端点
- ✅ 实现动态模型切换

现在您的系统完全支持动态配置多个 AI 模型了！🚀
